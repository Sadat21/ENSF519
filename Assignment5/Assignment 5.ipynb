{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSF 519.01 Applied Data Science \n",
    "**Assignment 5** - 100 marks\n",
    "\n",
    "**Due:** November 25, 05.00 pm.\n",
    "\n",
    "\n",
    "**IMPORTANT NOTE: each task must be implemented as asked, even if there are other easier or better solutions.**\n",
    "\n",
    "**How to deliver:**\n",
    "Edit this file and write your solutions in sections specified with `# Your solution`. Test your code and when you are done, submit this notebook as an `.ipynb` file to D2L dropbox. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam detection \n",
    "\n",
    "Here we have a dataset of text messages which are labeled as spam or ham. We want to read the dataset and use a clustering algorithm to tell spam messages from non-spam (ham!) ones. The data is in tsv format with two columns: label and text. TSV is just like csv but the column values are separated by a tab instead of a `,`. \n",
    "\n",
    "1. Read the file into a dataframe\n",
    "2. Convert `label` column to pandas categorical data type\n",
    "3. complete the `clean_text` function and apply it to the text column. To clean up:\n",
    "    1. Make it lowercase\n",
    "    2. Remove all of the punctuations (use `string.punctuation` and `str.translate`)\n",
    "    3. Replace repetetive whitespaces with just one blank charachter (e.g.: 'i    had \\tan apple' -> 'i had an apple')\n",
    "    4. Removing the stop words\n",
    "    5. Stem each word using snowball stemmer provided in `nltk`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    category\n",
      "text       object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>jurong point crazi avail bugi n great world la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor u c say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goe usf live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word id like fun tb ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>brother like speak treat like aid patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>request mell mell oru minnaminungint nurungu v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner valu network custom select receivea £90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month u r entitl updat latest colour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>im gonna home soon dont want talk stuff anymor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>chanc win cash 100 20000 pound txt csh11 send ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent won 1 week free membership £100000 priz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>ive search right word thank breather promis wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>date sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>xxxmobilemovieclub use credit click wap link t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>oh kim watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>eh u rememb 2 spell yes did v naughti make v wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>fine that way u feel that way gota b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>england v macedonia  dont miss goalsteam news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>serious spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>i'm go tri 2 month ha ha joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>ü pay lar da stock comin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>aft finish lunch str lor ard 3 smth lor u fini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>just forc eat slice im realli hungri tho suck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>lol convinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>did catch bus  fri egg  did make tea eat mom l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>im amp pack car ill let know there room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhh work vagu rememb doe feel like lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>armand say ass epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>u havent got urself jacket ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>im take derek amp taylor walmart im time your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>hi durban number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>ic lotta childporn car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>contract mobil 11 mnths latest motorola nokia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>tri weekend v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>know wot peopl wear t shirt jumper hat belt kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>cool time think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>wen did spiritu deep that great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>safe trip nigeria wish happi soon compani shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>hahahaus brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>mind ive got gas round trip bar sudden influx ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>yeh indian nice tho did kane bit shud 4 drink ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes that u text pshewmiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>meant calcul ltgt unit ltgt  school realli exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorri ill later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>arent ltgt hour imma flip shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>lor juz lor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>dump heap mom decid come low bore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lor soni ericsson salesman ask shuhui say q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>ard 6 like dat lor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>dont wait til wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>huh y lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>remind o2 250 pound free credit detail great o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>2nd time tri 2 contact u u won £750 pound priz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>ü b go esplanad fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>piti  mood soani suggest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>guy did bitch act like id interest buy week ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  jurong point crazi avail bugi n great world la...\n",
       "1      ham                              ok lar joke wif u oni\n",
       "2     spam  free entri 2 wkli comp win fa cup final tkts 2...\n",
       "3      ham                        u dun say earli hor u c say\n",
       "4      ham                        nah dont think goe usf live\n",
       "5     spam  freemsg hey darl 3 week word id like fun tb ok...\n",
       "6      ham           brother like speak treat like aid patent\n",
       "7      ham  request mell mell oru minnaminungint nurungu v...\n",
       "8     spam  winner valu network custom select receivea £90...\n",
       "9     spam  mobil 11 month u r entitl updat latest colour ...\n",
       "10     ham  im gonna home soon dont want talk stuff anymor...\n",
       "11    spam  chanc win cash 100 20000 pound txt csh11 send ...\n",
       "12    spam  urgent won 1 week free membership £100000 priz...\n",
       "13     ham  ive search right word thank breather promis wo...\n",
       "14     ham                                        date sunday\n",
       "15    spam  xxxmobilemovieclub use credit click wap link t...\n",
       "16     ham                                       oh kim watch\n",
       "17     ham   eh u rememb 2 spell yes did v naughti make v wet\n",
       "18     ham             fine that way u feel that way gota b\n",
       "19    spam  england v macedonia  dont miss goalsteam news ...\n",
       "20     ham                                      serious spell\n",
       "21     ham                      i'm go tri 2 month ha ha joke\n",
       "22     ham                           ü pay lar da stock comin\n",
       "23     ham  aft finish lunch str lor ard 3 smth lor u fini...\n",
       "24     ham                 ffffffffff alright way meet sooner\n",
       "25     ham  just forc eat slice im realli hungri tho suck ...\n",
       "26     ham                                        lol convinc\n",
       "27     ham  did catch bus  fri egg  did make tea eat mom l...\n",
       "28     ham            im amp pack car ill let know there room\n",
       "29     ham            ahhh work vagu rememb doe feel like lol\n",
       "...    ...                                                ...\n",
       "5542   ham                             armand say ass epsilon\n",
       "5543   ham                      u havent got urself jacket ah\n",
       "5544   ham  im take derek amp taylor walmart im time your ...\n",
       "5545   ham                                   hi durban number\n",
       "5546   ham                             ic lotta childporn car\n",
       "5547  spam  contract mobil 11 mnths latest motorola nokia ...\n",
       "5548   ham                                      tri weekend v\n",
       "5549   ham  know wot peopl wear t shirt jumper hat belt kn...\n",
       "5550   ham                                    cool time think\n",
       "5551   ham                    wen did spiritu deep that great\n",
       "5552   ham  safe trip nigeria wish happi soon compani shar...\n",
       "5553   ham                                hahahaus brain dear\n",
       "5554   ham  mind ive got gas round trip bar sudden influx ...\n",
       "5555   ham  yeh indian nice tho did kane bit shud 4 drink ...\n",
       "5556   ham                          yes that u text pshewmiss\n",
       "5557   ham  meant calcul ltgt unit ltgt  school realli exp...\n",
       "5558   ham                                    sorri ill later\n",
       "5559   ham                     arent ltgt hour imma flip shit\n",
       "5560   ham                                        lor juz lor\n",
       "5561   ham                  dump heap mom decid come low bore\n",
       "5562   ham  ok lor soni ericsson salesman ask shuhui say q...\n",
       "5563   ham                                 ard 6 like dat lor\n",
       "5564   ham                           dont wait til wednesday \n",
       "5565   ham                                          huh y lei\n",
       "5566  spam  remind o2 250 pound free credit detail great o...\n",
       "5567  spam  2nd time tri 2 contact u u won £750 pound priz...\n",
       "5568   ham                            ü b go esplanad fr home\n",
       "5569   ham                           piti  mood soani suggest\n",
       "5570   ham  guy did bitch act like id interest buy week ga...\n",
       "5571   ham                                          rofl true\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('sms.tsv', sep='\\t', header=None)\n",
    "df.columns = [\"label\", \"text\"]\n",
    "df['label'] = df['label'].astype(\"category\")\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: str, returns: str\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    words = map(lambda x: x.strip().lower().translate(str.maketrans('', '', string.punctuation)), words)\n",
    "    words = filter(lambda x: x not in ENGLISH_STOP_WORDS, words)\n",
    "    words = map(lambda x: stemmer.stem(x), words)\n",
    "    \n",
    "    new_text = ' '.join(words)\n",
    "    \n",
    "    # Your solution\n",
    "    return new_text\n",
    "\n",
    "df['text'] = df[\"text\"].apply(clean_text)\n",
    "sms = df\n",
    "# Your solution\n",
    "print(sms.dtypes)  # Expected: label category text object dtype: object\n",
    "sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test sets (20% test 80% training), use `stratify` parameter to ensure that there is an even split for both categories. X values should be the vectors and y values the labels.\n",
    "\n",
    "Similar to previous assignments and problems, change the random state in a for loop from 0 to 9, in each iteration:\n",
    "\n",
    "1. Create a TF-IDF vectorizer with `min_df` = 2. Vectorize the training set using its `fit_transform` method and store it in a variable. Use the same vectorizer and using the transform alone (without refitting the model) transform the test set.\n",
    "2. train and evaluate these classifiers: \n",
    "\n",
    "    * LogisticRegression \n",
    "    * LinearSVC\n",
    "    * Naïve Bayes, with Bernoulli distribution\n",
    "    * Decision tree, use 20 for `min_samples_split` to prevent overfitting\n",
    "    * Random Forest, with a 100 estimators and use min_samples_split like above\n",
    "\n",
    " \n",
    "\n",
    "Use `random_state`s from in `[0, 5)` in classifier contruction for those which accept this parameter.\n",
    "Keep record of these scores in a pandas dataframe and make a boxplot to compare them. Set ylim to `(0.85, 1)`. \n",
    "\n",
    "**You should do all these inside the fit_eval function. Don't add any lines of code before or after it.** Also it doesn't need to return any values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def fit_eval(vectors):\n",
    "    # Column names: 'Logistic Regression', 'Linear SVC', 'Naïve Bayes', 'Decision tree', 'Random Forest'\n",
    "    for split_seed in range(10):\n",
    "        X_train, X_test, y_train, y_test = ...\n",
    "        # Your solution\n",
    "    \n",
    "    # Should not return anything\n",
    "\n",
    "fit_eval(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `fit_eval` function again but this time instead of using the TF-IDF vectors directly, make an LDA with 25 topics and use topic coverage vector of each document (text message). Use 0 as the `random_state` and a `CountVectorizer` with `min_df` = 2 to vectorize the text messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_eval(lda_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `components_` attribute of the LDA to find top 5 words of each topic and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic in enumerate(lda.components_, start=1):\n",
    "    # Your solution\n",
    "    print('Top in '+str(i)+':', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few sentences describe your observations with regard to comparing vanilla TF-IDF vs adding a LDA on top of a count vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit `enter` to edit this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
