{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> <center> ENSF 519.01 Applied Data Scince </center></h1>\n",
    "<h2> <center> Term Test - Oct 23, 2019 </center></h2>\n",
    "<h2> <center> 100 marks - 2 hours </center></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your Full Name:` \n",
    "\n",
    "`Your Student ID:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (30 pts)\n",
    "\n",
    "To answer this question you need to use a text file called `medium.txt`, which contains a number of articles from the medium.com website. In this question, you will first find all the `numbers` in the text, then check the distribution of `last digits` of the the numbers, over the text. Complete the code below to implement the following tasks:\n",
    "\n",
    "1. Read the whole text file into a single string.\n",
    "2. Use a regular expression to find all the numbers (numbers may have \",\" like 100,000 or fraction like 13.5. you keep a clean version without comma and drop the fraction and decimal point like 100000 and 13 for the example above.\n",
    "3. Use `map` and a proper `lambda` expression to extract all the `last digits` (the rightmost digit) of all numbers as a list of integers. To give you an example, after applying the `map` on `['168', '54', '1000', '89']` you should get back `[8, 4, 0, 9]`. Note the data types!\n",
    "4. Use proper numpy methods to count number of occurences of each digit.\n",
    "5. Plot a bar chart showing how many numbers end with each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Open and read the contents of the given file. \n",
    "    Return the contents as a string. \n",
    "    Don't forget to properly close the file.\n",
    "    \"\"\"\n",
    "    file = open(file_name, \"r\")\n",
    "    bookString = file.read()\n",
    "    \n",
    "    return bookString\n",
    "\n",
    "def find_all_numbers(text):\n",
    "    \"\"\"\n",
    "    Using a regular expression find all the numbers in the given text\n",
    "    \"\"\"\n",
    "    \n",
    "    return ...\n",
    "\n",
    "def get_last_digits(numbers_list):\n",
    "    \"\"\" \n",
    "    Use `map` to get a list of rightmost digits in the input list. \n",
    "    Input type is a list of strings, the output should be a list of ints.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ...\n",
    "    \n",
    "def count_digits_in_list(l):\n",
    "    \"\"\"\n",
    "    Use proper numpy methods for counting the frequency of each item in the input list.\n",
    "    If the list is something like [2, 4, 4, 4, 6, 6, 6, 6, 6], the output will be something like:\n",
    "    {2: 1, 4: 3, 6: 5}, but not necesserily as a dictionary, though. You're free to return the results in \n",
    "    any data format that suits your solution.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ...\n",
    "\n",
    "def plot_bar_chart(last_digit_counts):\n",
    "    \"\"\"\n",
    "    The input has the same type as the output of count_digits_in_list. No return statement is necessary.\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "\n",
    "text = read_file('medium.txt')\n",
    "all_numbers = find_all_numbers(text)\n",
    "last_digits = get_last_digits(all_numbers)\n",
    "last_digit_counts = count_digits_in_list(last_digits)\n",
    "plot_bar_chart(last_digit_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (40 pts)\n",
    "\n",
    "Best non-fiction books of 2018 based on the good reads users votes can be found on this page: https://www.goodreads.com/choiceawards/best-nonfiction-books-2018\n",
    "\n",
    "1. Here is the code that downloadds the page html content and makes a beautiful soup parser on it. Note that we have copied the file in a different domain to avoid potential IP blocking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "page_html = requests.get('https://sea-lab.github.io/best-nonfiction-books-2018.html').text\n",
    "parser = BeautifulSoup(page_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are 20 blocks in the page showing the top 20 nominated books in the category. Find them using beautiful soup and loop over them to find:\n",
    "    1. The number of votes using RegEx, don't forget to convert it to an `int`.\n",
    "    2. Name of the book\n",
    "    3. The author name\n",
    "2. Store these three pieces of information in a pandas dataframe\n",
    "3. Add a column to the dataframe that stores the genre. The code that extracts the genre name from the page is already included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_books_info(parser):\n",
    "    \"\"\"\n",
    "    Get the page parser and find all the books\n",
    "    \"\"\"\n",
    "    genre_name = parser.find('div', class_='gcaMastheader').get_text()[len('Best '):]\n",
    "    \n",
    "    return ...  # \n",
    "\n",
    "nonfiction = extract_books_info(parser)\n",
    "nonfiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read a similar dataframe from a csv file (fiction_books.csv) for top 20 fiction books. Then\n",
    "\n",
    "1. Append the dataframes together (the result will have the same 4 columns, and 40 rows - and indexed from 0 to 39)\n",
    "\n",
    "2. Sort it by #votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined = ...\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas `groupby` and aggregation on the combined dataframe find the total number of votes for each genre. Then plot a bar chart with just two columns showing the number of votes for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (30 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the attached csv file (auto-mpg-cleaned.csv) that contains information about a number of car models. Split it into features and target columns. The target column is `mpg` and there are 7 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "print(target.shape)  # Expected (392, 1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a linear regresson model 50 times each with a different train-test split (test_size=0.25, random states: [1, 50)). Report the average score on the training and test sets, over these 50 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply a Lasso regularizatoin with 7 values of alpha: `[0.001, 0.01, 0.1, 1.0, 10., 100., 1000.]`. For each alpha use integers in [1, 50) as the train-test split's random state. Report the average score on the training and test sets per alpha. Explain where the sweet spot is with respect to over-fitting and under-fitting tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for alpha in [0.001, 0.01, 0.1, 1.0, 10., 100., 1000.]:\n",
    "    # Your code\n",
    "    print(f'LA ‚ç∫={alpha:.5}\\tTrain={train_mean_score:.6}\\tTest={test_mean_score:.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explain your answer here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
