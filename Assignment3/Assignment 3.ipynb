{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSF 519.01 Applied Data Science \n",
    "**Assignment 3** - 100 marks\n",
    "\n",
    "**Due:** November 1st, 04.00 pm.\n",
    "\n",
    "\n",
    "**IMPORTANT NOTE: each task must be implemented as asked, even if there are other easier or better solutions.**\n",
    "\n",
    "**How to deliver:**\n",
    "Edit this file and write your solutions in sections specified with `# Your solution`. Test your code and when you are done, submit this notebook as an `.ipynb` file to D2L dropbox. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1: Heart disease diagnosis (75 points)\n",
    "\n",
    "In this problem you are presented with a tabular dataset with 13 attributes that are thought to be good indicators of a heart diseases. We are going to train a number of clustering and binary classification algorithms on these data and see which ones perform better. \n",
    "\n",
    "The dataset is stored in CSV format. Use pandas `read_csv` to load it in python. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "source_file = 'heart.csv'\n",
    "data = # Your solution\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the last column, `target`, indicates if the patient had a heart disease. That column is used as the label and the rest are features in a 13-dimensional feature space. Separate the labels column from the rest of the dataset. (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n",
    "\n",
    "print(features.shape, labels.shape)  # Expected: (303, 13) (303,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best classifiers\n",
    "\n",
    "We want to compare the average performance of the algorithms. To make the comparison fair they need to be evaluated on the same training and test data, in other words we need to control the randomness in training/test data split. So we use a set of *fixed random seeds* for test and train splitting. (15 points)\n",
    "\n",
    "1. Using `sklearn` split the data in two chunks, 1/4 and 3/4, looping over the predefined random seeds(from 5000 to 5051).\n",
    "2. In each iteration create a `LogisticRegression` (use `liblinear` solver) and a `KNeighborsClassifier` (k=10) then train them on the training data.\n",
    "3. In each iteration, evaluate the classifiers on the data and record their scores in the `scores` dictionary.\n",
    "4. Convert the dictionary into a pandas dataframe and call `boxplot` on the dataframe to draw a boxplot of the data. Set the y axis range to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with the current settings, logistic regression outperforms KNN algorithm. Let's see if we can help KNN to get better. We'll keep the random seed as a fixed number (5026) and experiment with different values for `k`. \n",
    "\n",
    "### Improving KNN\n",
    "(20 points)\n",
    "\n",
    "1. Split the data into training and testing chunks.\n",
    "2. Train a logistic regression classifier on the training data, then evaluate it on the test data and store the value in `lr_score` variable. This is only used for comparison.\n",
    "3. Complete the test_knn function below:\n",
    "\n",
    "    1. Use a for loop to iterate through `k_range`, use these values for parameter `k` and train a KNN classifier. Pass all `knn_params` as keyword arguments to `KNeighboursClassifier`.\n",
    "    2. Create a 3-tuple (k, train_score, test_score) and append it to scores list where train_score and test_score are the results of evaluating the classifier on the training and test data. \n",
    "    3. Convert the list of tuples into a pandas dataframe. Set appropriate column names, use `k` as the index.\n",
    "\n",
    "4. Call test_knn and store the results in a variable. Use odd numbers from 3 to 25 as the first parameter.\n",
    "5. Plot the accuracy scores. Add a horizontal dashed line to show the value of `lr_score` on the same plot. It would be nicer if you used another color for this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 5026\n",
    "# Your solution\n",
    "\n",
    "def test_knn(k_range, X_train, X_test, y_train, y_test, **knn_params):\n",
    "\n",
    "    return ...  # Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that with different values for K we can find the sweet spot between overfitting and generalization in KNN but it never gets good enough to beat logistic regression.\n",
    "\n",
    "We can change also experiment with changing the [`weights` parameter](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) in KNN from its default `uniform` value to `distance`. Call the `test_knn` function again with the same range for `k`, this time passing `weights` parameter as well. Plot the training and test scores as well as the horizontal dashed line that shows `lr_score`. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it's overfitting, it performs better on the test set than the previous one. Yet, it's no better than logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the models (ensemble model)\n",
    "\n",
    "A common way of maximizing the accuracy is to train multiple models and use all for prediction. In a classification problem we use the class that the majority of models have predicted and in a regression problem a weighted average of the predictions is used.\n",
    "\n",
    "Make a function that creates and trains 3 models and returns them in a list. The models are:\n",
    "\n",
    "* A Logistic Regressor with 'liblinear' solver\n",
    "* A KNN classifiers with k = 10 and setting `weights` to 'distance'\n",
    "* Another KNN with k = 20 and setting `weights` to 'distance'\n",
    "\n",
    "and the inputs to the function are X and Y values for the training set. (12 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(X_train, y_train):\n",
    "    # Your solution\n",
    "    return ...\n",
    "\n",
    "models = create_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `predict` function that takes in a list of models and the input vectors (X) and returns the output vector Y using majority voting. To find the majority in an easy way use `mode` function in `scipy` since it supports vectorized operations. (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def predict(models, X):\n",
    "    # Your solution\n",
    "    return ...\n",
    "    \n",
    "predict(models, X_test)  # Expected: 0, 1, 1, 1, 1, 0, 0, 0, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a loop similar to the first part (Finding the best classifiers) to compare the performance of each of the models in the ensemble (=the model list created by `create_models`) and the combined model (call the `predict` function above). To evaluate the accuracy of the combined model use `sklearn.metrics.accuracy_score` method. Draw the boxplot in the end. (13 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Your solution\n",
    "# Use LR, KNN15, KNN20, and Combined for the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the result get better than the individual KNN models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem2: Bike sharing (25 points)\n",
    "\n",
    "In this problem we are going to use linear regression to predict the number of bike sharif platfor quality of wine from 1-10. Read the data from CSV file, use 'cnt' column as the target values and all other columns (except 'dteday') as the features (4 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "# Your solution\n",
    "\n",
    "print(features.shape, target.shape) # Expected: (731, 11) (731,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in two 1/4 and 3/4 chunks for training and testing, use the number 15 as the `random_state` parameter. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a linear regression model on the data and report the training and test scores. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n",
    "training_score = ...\n",
    "test_score = ...\n",
    "print(f'Training={training_score:.4}\\tTest={test_score:.4}')  # Expected: Training=0.7857\tTest=0.7989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularize the regression model using ridge method. Train it with 10 values of alpha and report training and test scores. (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [1e-3, 1e-2, 1e-1, 1., 2., 5., 10., 20., 50., 100.]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    # Your solution\n",
    "    \n",
    "    training_score = ...\n",
    "    test_score = ...\n",
    "    print(f'⍺={alpha:.5}\\tTraining={training_score:.4}\\tTest={test_score:.4}')\n",
    "\n",
    "# First line of expected value:\n",
    "# ⍺=0.001\tTraining=0.7858\tTest=0.7989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same alpha values, train a lasso regualizer this time. Report the names of the features that got a 0 coefficient after regulazition. Separate their names with a comma, if none of them were omitted report 'no features'. (9 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [1e-3, 1e-2, 1e-1, 1., 2., 5., 10., 20., 50., 100.]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    # Your solution\n",
    "    \n",
    "    training_score = ...\n",
    "    test_score = ...\n",
    "    zeroed_out_feature_names = ....\n",
    "    print(f'⍺={alpha:.5}\\tTraining={training_score:.4}\\tTest={test_score:.4}\\t{zeroed_out_feature_names}')\n",
    "    \n",
    "# First line of expected value:\n",
    "# ⍺=0.001\tTraining=0.7857\tTest=0.7989\tno features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
